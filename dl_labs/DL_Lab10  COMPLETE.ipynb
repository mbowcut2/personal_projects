{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "DL_Lab10.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "sBOvJdJfkXIL",
        "kFoEeTYHDq2s",
        "7z6g7a_Y84n0",
        "TBigIUFTukeJ",
        "zcz0JGXjxFGe",
        "2vJVbYcAJAf2",
        "gMOzGDND9FD1",
        "eOtl8z8G9wbr",
        "2Krh0eYy18R9",
        "aEDv_-H7BvM0",
        "YH5mQBaa-_0b",
        "XMKRI77_-8nc",
        "qBT5jgifC7Im",
        "_K7F19SPQo6U",
        "9YLXvK51RnuL",
        "AHmjSVf_FNHv",
        "gPXJkNubFyY6",
        "iD45m3IwF9hh",
        "usQE-rSPZq_X",
        "IoA0tZZCa_1k",
        "8pa5vFJ5EUjv"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rEwpv0GZ_CrT"
      },
      "source": [
        "<a \n",
        "href=\"https://colab.research.google.com/github/wingated/cs474_labs_f2019/blob/master/DL_Lab10.ipynb\"\n",
        "  target=\"_parent\">\n",
        "  <img\n",
        "    src=\"https://colab.research.google.com/assets/colab-badge.svg\"\n",
        "    alt=\"Open In Colab\"/>\n",
        "</a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xnoEhAVvBcMj"
      },
      "source": [
        "# Lab 10: Transfer Learning/Fine-Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBOvJdJfkXIL"
      },
      "source": [
        "## Description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiuvTUWOjtBC"
      },
      "source": [
        "### Objective\n",
        "\n",
        "- Gain experience fine-tuning pre-trained models to domain-specific applications.\n",
        "\n",
        "### Deliverable\n",
        "\n",
        "For this lab you will submit an IPython notebook via Learning Suite. The bulk of the work is in modifying fine-tuning a pre-trained ResNet. Fine-tuning the GPT-2 language model is pretty easy. The provided code works as is; you will just have to swap in your own text dataset.\n",
        "\n",
        "### Grading\n",
        "\n",
        "- 35% Create a dataset class for your own dataset\n",
        "- 35% Create a network class that wraps a pretrained ResNet\n",
        "- 20% Implement unfreezing in the network class\n",
        "- 10% Fine-tune GPT-2 on your own dataset\n",
        "\n",
        "### Tips\n",
        "- Your life will be better if you download a dataset that already has the data in the expected format for ImageFolder (make sure to read the documentation!). The datasets recommended below are in the correct format.\n",
        "- Get the CNN working on the provided dataset (bird species classification) before swapping in your own.\n",
        "- For reference on freezing/unfreezing network weights, see [this github gist](https://gist.github.com/jcjohnson/6e41e8512c17eae5da50aebef3378a4c)\n",
        "- Check PyTorch's documentation to learn the difference between `requires_grad=False` and `requires_grad_(False)`.\n",
        "- For training GPT-2, first try the medium-size (355M parameter) model. If your Colab instance doesn't have enough GPU space, you may need to switch to the small-size (124M parameter) model, but the results will be less impressive."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dKzRORuLBNLR"
      },
      "source": [
        "from torchvision.models import resnet152\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "import torch\n",
        "from torch import optim, nn\n",
        "import zipfile\n",
        "from google.colab import files\n",
        "import os\n",
        "import sys\n",
        "from PIL import Image, ImageOps\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4R3D8Mr8b54"
      },
      "source": [
        "## 1 Fine-tune a ResNet for image classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFoEeTYHDq2s"
      },
      "source": [
        "### 1.1 Find a dataset to fine-tune on, and make a Dataset class (1 hr.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7z6g7a_Y84n0"
      },
      "source": [
        "#### TODO:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P8NtFZRd5hcm"
      },
      "source": [
        "- Inherit from torch.utils.data.Dataset\n",
        "- Use a [torchvision.datasets.ImageFolder](https://pytorch.org/docs/stable/torchvision/datasets.html#torchvision.datasets.ImageFolder)\n",
        "- Don't spend too long finding another dataset. Some suggestions that you are free to use:\n",
        " - https://www.kaggle.com/jessicali9530/stanford-dogs-dataset\n",
        " - https://www.kaggle.com/puneet6060/intel-image-classification\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBigIUFTukeJ"
      },
      "source": [
        "#### Help for downloading kaggle datasets\n",
        "Downloading Kaggle datasets requires authentication, so you can't just download from a url. Here are some step-by-step instructions of how to get Kaggle datasets in Colab"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_X29UC6CvwfQ"
      },
      "source": [
        "1. Create an API key in Kaggle\n",
        "    - Click on profile photo\n",
        "    - Go to 'My Account'\n",
        "    - Scroll down to the API access section and click \"Create New API Token\"\n",
        "    - `kaggle.json` is now downloaded to your computer\n",
        "\n",
        "2. Upload the API key and install the Kaggle API client by running the next cell (run it again if it throws an error the first time). Also, `files.upload()` may not work in Firefox. One solution is to expand the Files banner (indicated by the '>' tab on the left side of the page) and use that to upload the key."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 89
        },
        "id": "Mhjc0pM7jOoZ",
        "outputId": "0cd33ab8-0856-4100-893f-a621d94a847e"
      },
      "source": [
        "# Run this cell and select the kaggle.json file downloaded\n",
        "# from the Kaggle account settings page.\n",
        "from google.colab import files\n",
        "files.upload()\n",
        "# Next, install the Kaggle API client.\n",
        "!pip install -q kaggle\n",
        "# Let's make sure the kaggle.json file is present.\n",
        "!ls -lha kaggle.json\n",
        "# The Kaggle API client expects this file to be in ~/.kaggle,\n",
        "# so move it there.\n",
        "!mkdir -p ~/.kaggle\n",
        "!mv kaggle.json ~/.kaggle/\n",
        "# This permissions change avoids a warning on Kaggle tool startup.\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9fa677ca-2f27-4c54-8dcf-711a94015056\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9fa677ca-2f27-4c54-8dcf-711a94015056\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving kaggle.json to kaggle.json\n",
            "-rw-r--r-- 1 root root 63 Nov  6 20:12 kaggle.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AGlIa4SIwEXB"
      },
      "source": [
        "3. Copy the desired dataset locally"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7HtB-XdIr1EE",
        "outputId": "b17a54da-7953-445a-a012-5b7dad175f69"
      },
      "source": [
        "# Example download command for dataset found here: https://www.kaggle.com/akash2907/bird-species-classification\n",
        "!kaggle datasets download -d akash2907/bird-species-classification"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading bird-species-classification.zip to /content\n",
            " 99% 1.36G/1.37G [00:09<00:00, 160MB/s]\n",
            "100% 1.37G/1.37G [00:10<00:00, 146MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "apXCsWyUeq-Q",
        "outputId": "4c68b83d-cd08-4521-cfdb-f18cfeaeee8b"
      },
      "source": [
        "!kaggle datasets download -d jessicali9530/stanford-dogs-dataset"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading stanford-dogs-dataset.zip to /content\n",
            " 98% 734M/750M [00:05<00:00, 153MB/s]\n",
            "100% 750M/750M [00:05<00:00, 143MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcz0JGXjxFGe"
      },
      "source": [
        "#### Make the Dataset class\n",
        "See the implementation below for reference, and implement a dataset class for the dataset you choose."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lthPlsGeK4CX"
      },
      "source": [
        "class BirdDataset(Dataset):\n",
        "    def __init__(self, zip_file='bird-species-classification.zip', size=256, train=True, upload=False):\n",
        "        super(BirdDataset, self).__init__()\n",
        "        \n",
        "        self.train = train\n",
        "        extract_dir = os.path.splitext(zip_file)[0]\n",
        "        if not os.path.exists(extract_dir):\n",
        "            os.makedirs(extract_dir)\n",
        "            self.extract_zip(zip_file, extract_dir)\n",
        "            # Resize the images - originally they are high resolution. We could do this\n",
        "            # in the DataLoader, but it will read the full-resolution files from disk\n",
        "            # every time before resizing them, making training slow\n",
        "            self.resize(extract_dir, size=size)\n",
        "\n",
        "        postfix = 'train' if train else 'test'\n",
        "            \n",
        "        if train:\n",
        "            # The bird-species dataset mistakenly has a train_data folder inside of train_data\n",
        "            self.dataset_folder = datasets.ImageFolder(os.path.join(extract_dir, 'train_data', 'train_data'), transform=transforms.Compose([transforms.ToTensor()]))\n",
        "        else:\n",
        "            self.dataset_folder = datasets.ImageFolder(os.path.join(extract_dir, 'test_data', 'test_data'), transform=transforms.Compose([transforms.ToTensor()]))\n",
        "\n",
        "    def extract_zip(self, zip_file, extract_dir):\n",
        "        print(\"Extracting\", zip_file)\n",
        "        with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
        "            zip_ref.extractall(extract_dir)\n",
        "\n",
        "    def resize(self, path, size=256):\n",
        "        \"\"\"Resizes all images in place\"\"\"\n",
        "        print(\"Resizing images\")\n",
        "        dirs = os.walk(path)\n",
        "        for root, dirs, files in os.walk(path):\n",
        "            for item in files:\n",
        "                name = os.path.join(root, item)\n",
        "                if os.path.isfile(name):\n",
        "                    im = Image.open(name)\n",
        "                    im = ImageOps.fit(im, (size, size))\n",
        "                    im.save(name[:-3] + 'bmp', 'BMP')\n",
        "                    os.remove(name)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return self.dataset_folder[i]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset_folder)\n",
        "\n",
        "bird_data = BirdDataset()"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jHFdToeDtIF"
      },
      "source": [
        "#########################\n",
        "# Implement your own Dataset\n",
        "#########################\n",
        "class CustomDataset(Dataset):\n",
        "    def __init__(self, zip_file='stanford-dogs-dataset.zip', size=256, train=True, upload=False):\n",
        "        super(CustomDataset, self).__init__()\n",
        "        \n",
        "        self.train = train\n",
        "        extract_dir = os.path.splitext(zip_file)[0]\n",
        "        if not os.path.exists(extract_dir):\n",
        "            os.makedirs(extract_dir)\n",
        "            self.extract_zip(zip_file, extract_dir)\n",
        "            # Resize the images - originally they are high resolution. We could do this\n",
        "            # in the DataLoader, but it will read the full-resolution files from disk\n",
        "            # every time before resizing them, making training slow\n",
        "            self.resize(extract_dir, size=size)\n",
        "\n",
        "        postfix = 'train' if train else 'test'\n",
        "            \n",
        "        if train:\n",
        "            # The bird-species dataset mistakenly has a train_data folder inside of train_data\n",
        "            self.dataset_folder = datasets.ImageFolder(os.path.join(extract_dir, 'train_data', 'train_data'), transform=transforms.Compose([transforms.ToTensor()]))\n",
        "        else:\n",
        "            self.dataset_folder = datasets.ImageFolder(os.path.join(extract_dir, 'test_data', 'test_data'), transform=transforms.Compose([transforms.ToTensor()]))\n",
        "\n",
        "\n",
        "\n",
        "    def extract_zip(self, zip_file, extract_dir):\n",
        "        print(\"Extracting\", zip_file)\n",
        "        with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
        "            zip_ref.extractall(extract_dir)\n",
        "\n",
        "    def resize(self, path, size=256):\n",
        "        \"\"\"Resizes all images in place\"\"\"\n",
        "        print(\"Resizing images\")\n",
        "        dirs = os.walk(path)\n",
        "        for root, dirs, files in os.walk(path):\n",
        "            for item in files:\n",
        "                name = os.path.join(root, item)\n",
        "                if os.path.isfile(name):\n",
        "                    im = Image.open(name)\n",
        "                    im = ImageOps.fit(im, (size, size))\n",
        "                    im.save(name[:-3] + 'bmp', 'BMP')\n",
        "                    os.remove(name)\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        return self.dataset_folder[i]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset_folder)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2vJVbYcAJAf2"
      },
      "source": [
        "### 1.2 Wrap a pretrained ResNet in an `nn.Module` (30 min)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMOzGDND9FD1"
      },
      "source": [
        "#### TODO:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jLvmDHbl9IyG"
      },
      "source": [
        "- Make a model class that inherits from `nn.Module`\n",
        "- Wrap a pretrained ResNet and swap out the last layer of that network with a layer that maps to the number of classes in your new dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V9MeV7fukLoc",
        "outputId": "2feb52c6-7134-4051-fb15-209ec5c14ea0"
      },
      "source": [
        "testModel = resnet152(pretrained=True)\n",
        "print(testModel)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (4): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (5): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (6): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (7): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (4): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (5): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (6): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (7): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (8): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (9): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (10): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (11): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (12): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (13): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (14): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (15): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (16): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (17): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (18): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (19): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (20): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (21): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (22): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (23): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (24): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (25): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (26): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (27): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (28): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (29): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (30): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (31): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (32): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (33): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (34): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (35): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NF_H3aMhk696",
        "outputId": "b034437f-e9a3-4062-bc25-441bd5d54a3d"
      },
      "source": [
        "testModel.fc"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=2048, out_features=1000, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eOtl8z8G9wbr"
      },
      "source": [
        "#### Make your model class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AY-XU4Mwas0j"
      },
      "source": [
        "class CustomResNet(nn.Module):\n",
        "    def __init__(self, num_classes, start_frozen=False):\n",
        "        super(CustomResNet, self).__init__()\n",
        "\n",
        "        # Part 1.2\n",
        "        # Load the model - make sure it is pre-trained\n",
        "        self.model = resnet152(pretrained=True)\n",
        "\n",
        "\n",
        "        # Part 1.4\n",
        "        if start_frozen:\n",
        "            # Turn off all gradients of the resnet\n",
        "            self.model.requires_grad_(False) #TODO: DOUBLE CHECK THIS\n",
        "        \n",
        "        # Part 1.2\n",
        "        # Look at the code of torchvision.models.resnet152 (or print the ResNet object) to find the name of the attribute to override (the last layer of the ResNet)\n",
        "        # Override the output linear layer of the neural network to map to the correct number of classes. Note that this new layer has requires_grad = True\n",
        "        self.model.fc = nn.Linear(in_features=2048, out_features=120, bias=True)\n",
        "        \n",
        "    def unfreeze(self, n_layers):\n",
        "        # Part 1.4\n",
        "        # Turn on gradients for the last n_layers\n",
        "\n",
        "        parameterList = list(self.model.parameters())[::-1]\n",
        "        for i in range(2*n_layers):\n",
        "          parameterList[i].requires_grad_(True)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Part 1.2\n",
        "        # Pass x through the resnet\n",
        "        return self.model(x)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Krh0eYy18R9"
      },
      "source": [
        "### 1.3 Read through and run this training loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yOGrrw2gbIPf"
      },
      "source": [
        "def accuracy(y_hat, y_truth):\n",
        "    \"\"\"Gets average accuracy of a vector of predictions\"\"\"\n",
        "    \n",
        "    preds = torch.argmax(y_hat, dim=1)\n",
        "    acc = torch.mean((preds == y_truth).float())\n",
        "    return acc\n",
        "\n",
        "def evaluate(model, objective, val_loader, device):\n",
        "    \"\"\"Gets average accuracy and loss for the validation set\"\"\"\n",
        "\n",
        "    val_losses = 0\n",
        "    val_accs = 0\n",
        "    batches = 0\n",
        "    # model.eval() so that batchnorm and dropout work in eval mode\n",
        "    model.eval()\n",
        "    # torch.no_grad() to turn off computation graph creation. This allows for temporal\n",
        "    # and spatial complexity improvements, which allows for larger validation batch \n",
        "    # sizes so it’s recommended\n",
        "    with torch.no_grad():\n",
        "        for x, y_truth in val_loader:\n",
        "            \n",
        "            batches += 1\n",
        "\n",
        "            x, y_truth = x.to(device), y_truth.to(device)\n",
        "            y_hat = model(x)\n",
        "            val_loss = objective(y_hat, y_truth)\n",
        "            val_acc = accuracy(y_hat, y_truth)\n",
        "\n",
        "            val_losses += val_loss.item()\n",
        "            val_accs += val_acc\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    return val_losses/batches, val_accs/batches"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKESMcKi2E_f"
      },
      "source": [
        "def train(start_frozen=False, model_unfreeze=0):\n",
        "    \"\"\"Fine-tunes a CNN\n",
        "    Args:\n",
        "        start_frozen (bool): whether to start with the network weights frozen.\n",
        "        model_unfreeze (int): the maximum number of network layers to unfreeze\n",
        "    \"\"\"\n",
        "    epochs = 20\n",
        "    # Start with a very low learning rate\n",
        "    lr = .00005\n",
        "    val_every = 3\n",
        "    num_classes = 16\n",
        "    batch_size = 32\n",
        "    device = torch.device('cuda:0')\n",
        "\n",
        "    # Data\n",
        "    # TODO: Use your own dataset\n",
        "    #train_dataset = CustomDataset(upload=True, train=True)\n",
        "    #val_dataset = CustomDataset(upload=True, train=False)\n",
        "    train_dataset = BirdDataset(upload=True, train=True)\n",
        "    val_dataset = BirdDataset(upload=True, train=False)\n",
        "\n",
        "    #subList = list(range(1, len(trainset), 2))\n",
        "    #train_subset = torch.utils.data.Subset(train_dataset, subList)\n",
        "    #val_subset = torch.utils.data.Subset(val_dataset,subList)\n",
        "\n",
        "    train_loader = DataLoader(train_dataset,\n",
        "                              shuffle=True,\n",
        "                              num_workers=8,\n",
        "                              batch_size=batch_size)\n",
        "    val_loader = DataLoader(val_dataset,\n",
        "                              shuffle=True,\n",
        "                              num_workers=8,\n",
        "                              batch_size=batch_size)\n",
        "    \n",
        "    # Model\n",
        "    model = CustomResNet(num_classes, start_frozen=start_frozen).to(device)\n",
        "    \n",
        "    # Objective\n",
        "    objective = nn.CrossEntropyLoss()\n",
        "    # Optimizer\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr, weight_decay=1e-1)\n",
        "\n",
        "    # Progress bar\n",
        "    pbar = tqdm(total=len(train_loader) * epochs)\n",
        "\n",
        "    train_losses = []\n",
        "    train_accs = []\n",
        "    val_losses = []\n",
        "    val_accs = []\n",
        "    \n",
        "    cnt = 0\n",
        "    for epoch in range(epochs):\n",
        "\n",
        "        # Implement model unfreezing\n",
        "        if epoch < model_unfreeze:\n",
        "            # Part 1.4\n",
        "            # Unfreeze the last layers, one more each epoch\n",
        "            model.unfreeze(epoch)\n",
        "        \n",
        "        for x, y_truth in train_loader:\n",
        "        \n",
        "            x, y_truth = x.to(device), y_truth.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            y_hat = model(x)\n",
        "            train_loss = objective(y_hat, y_truth)\n",
        "            train_acc = accuracy(y_hat, y_truth)\n",
        "\n",
        "            train_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            train_accs.append(train_acc)\n",
        "            train_losses.append(train_loss.item())\n",
        "\n",
        "            if cnt % val_every == 0:\n",
        "                val_loss, val_acc = evaluate(model, objective, val_loader, device)\n",
        "                val_losses.append(val_loss)\n",
        "                val_accs.append(val_acc)\n",
        "\n",
        "            pbar.set_description('train loss:{:.4f}, train accuracy:{:.4f}.'.format(train_loss.item(), train_acc))\n",
        "            pbar.update(1)\n",
        "            cnt += 1\n",
        "\n",
        "    pbar.close()\n",
        "    plt.subplot(121)\n",
        "    plt.plot(np.arange(len(train_accs)), train_accs, label='Train Accuracy')\n",
        "    plt.plot(np.arange(len(train_accs), step=val_every), val_accs, label='Val Accuracy')\n",
        "    plt.legend()\n",
        "    plt.subplot(122)\n",
        "    plt.plot(np.arange(len(train_losses)), train_losses, label='Train Loss')\n",
        "    plt.plot(np.arange(len(train_losses), step=val_every), val_losses, label='Val Loss')\n",
        "    plt.legend()\n",
        "    plt.show()  "
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 337
        },
        "id": "fvnxeLotchiH",
        "outputId": "ab727601-2f5e-46a2-f6bd-219eb13e750e"
      },
      "source": [
        "train(start_frozen=False, model_unfreeze=0)  "
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "train loss:0.2043, train accuracy:1.0000.: 100%|██████████| 100/100 [05:50<00:00,  3.51s/it]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEDv_-H7BvM0"
      },
      "source": [
        "### 1.4 Implement Unfreezing (1 hr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YH5mQBaa-_0b"
      },
      "source": [
        "#### Description"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u_YmE1pe-6LF"
      },
      "source": [
        "Unfreezing is a technique that can be helpful when fine tuning a CNN for a more difficult task with a large amount of data.\n",
        "\n",
        "The idea is that if we allow the network to tweak the earliest layers immediately, before the last FCL has been trained at all, the earliest layers will forget all of the useful features that they learned in order  to provide features that are helpful for the (untrained) FCL.\n",
        "\n",
        "So, rather than training all of the model weights at once, we learn the last fully connected layer, then train that layer together with the second-to-last layer, gradually adding layers until we reach the first layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XMKRI77_-8nc"
      },
      "source": [
        "#### TODO:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KaUc8BTYC1bz"
      },
      "source": [
        "- Modify your model's parameters by setting the `requires_grad` attributes to `False`. (but keep `requires_grad = True` for the last layer).\n",
        "- Add a member function to you model class that allows the user to unfreeze weights in the training loop. See [this github gist](https://gist.github.com/jcjohnson/6e41e8512c17eae5da50aebef3378a4c) for reference.\n",
        "- Modify your training loop to add logic that calls the `unfreeze` function of the model class: unfreeze one layer (a convolutional layer or linear layer, not the sequential or bottleneck layers) every epoch.\n",
        "- Call your train function to fine-tune the ResNet on your dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qBT5jgifC7Im"
      },
      "source": [
        "#### Call your train function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Mg9ySEO_BNDx",
        "outputId": "45bd5e44-a6bc-46ce-d35d-f0f72051d84b"
      },
      "source": [
        "############################\n",
        "# train with unfreezing here (should be a single call to your train function)\n",
        "############################\n",
        "train(start_frozen=True, model_unfreeze=20)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "\n",
            "  0%|          | 0/100 [00:00<?, ?it/s]\u001b[A\n",
            "train loss:4.8591, train accuracy:0.0000.:   0%|          | 0/100 [00:05<?, ?it/s]\u001b[A\n",
            "train loss:4.8591, train accuracy:0.0000.:   1%|          | 1/100 [00:05<09:01,  5.47s/it]\u001b[A\n",
            "train loss:4.8138, train accuracy:0.0000.:   1%|          | 1/100 [00:06<09:01,  5.47s/it]\u001b[A\n",
            "train loss:4.8138, train accuracy:0.0000.:   2%|▏         | 2/100 [00:06<04:19,  2.65s/it]\u001b[A\n",
            "train loss:4.8014, train accuracy:0.0000.:   2%|▏         | 2/100 [00:06<04:19,  2.65s/it]\u001b[A\n",
            "train loss:4.8014, train accuracy:0.0000.:   3%|▎         | 3/100 [00:06<02:48,  1.74s/it]\u001b[A\n",
            "train loss:4.6556, train accuracy:0.0312.:   3%|▎         | 3/100 [00:11<02:48,  1.74s/it]\u001b[A\n",
            "train loss:4.6556, train accuracy:0.0312.:   4%|▍         | 4/100 [00:11<04:37,  2.89s/it]\u001b[A\n",
            "train loss:4.6005, train accuracy:0.0000.:   4%|▍         | 4/100 [00:12<04:37,  2.89s/it]\u001b[A\n",
            "train loss:4.6005, train accuracy:0.0000.:   5%|▌         | 5/100 [00:12<03:16,  2.07s/it]\u001b[A\n",
            "train loss:4.5741, train accuracy:0.0000.:   5%|▌         | 5/100 [00:13<03:16,  2.07s/it]\u001b[A\n",
            "train loss:4.5741, train accuracy:0.0000.:   6%|▌         | 6/100 [00:13<02:54,  1.86s/it]\u001b[A\n",
            "train loss:4.4344, train accuracy:0.0000.:   6%|▌         | 6/100 [00:18<02:54,  1.86s/it]\u001b[A\n",
            "train loss:4.4344, train accuracy:0.0000.:   7%|▋         | 7/100 [00:18<04:17,  2.77s/it]\u001b[A\n",
            "train loss:4.3852, train accuracy:0.0000.:   7%|▋         | 7/100 [00:18<04:17,  2.77s/it]\u001b[A\n",
            "train loss:4.3852, train accuracy:0.0000.:   8%|▊         | 8/100 [00:18<03:13,  2.10s/it]\u001b[A\n",
            "train loss:4.2890, train accuracy:0.0625.:   8%|▊         | 8/100 [00:19<03:13,  2.10s/it]\u001b[A\n",
            "train loss:4.2890, train accuracy:0.0625.:   9%|▉         | 9/100 [00:19<02:30,  1.65s/it]\u001b[A\n",
            "train loss:4.3684, train accuracy:0.0909.:   9%|▉         | 9/100 [00:24<02:30,  1.65s/it]\u001b[A\n",
            "train loss:4.3684, train accuracy:0.0909.:  10%|█         | 10/100 [00:24<03:49,  2.55s/it]\u001b[A\n",
            "train loss:4.1780, train accuracy:0.0312.:  10%|█         | 10/100 [00:25<03:49,  2.55s/it]\u001b[A\n",
            "train loss:4.1780, train accuracy:0.0312.:  11%|█         | 11/100 [00:25<03:17,  2.22s/it]\u001b[A\n",
            "train loss:4.1332, train accuracy:0.0625.:  11%|█         | 11/100 [00:26<03:17,  2.22s/it]\u001b[A\n",
            "train loss:4.1332, train accuracy:0.0625.:  12%|█▏        | 12/100 [00:26<02:33,  1.75s/it]\u001b[A\n",
            "train loss:4.1236, train accuracy:0.0000.:  12%|█▏        | 12/100 [00:30<02:33,  1.75s/it]\u001b[A\n",
            "train loss:4.1236, train accuracy:0.0000.:  13%|█▎        | 13/100 [00:30<03:49,  2.63s/it]\u001b[A\n",
            "train loss:4.0946, train accuracy:0.0312.:  13%|█▎        | 13/100 [00:31<03:49,  2.63s/it]\u001b[A\n",
            "train loss:4.0946, train accuracy:0.0312.:  14%|█▍        | 14/100 [00:31<02:55,  2.04s/it]\u001b[A\n",
            "train loss:4.0095, train accuracy:0.0000.:  14%|█▍        | 14/100 [00:32<02:55,  2.04s/it]\u001b[A\n",
            "train loss:4.0095, train accuracy:0.0000.:  15%|█▌        | 15/100 [00:32<02:16,  1.61s/it]\u001b[A\n",
            "train loss:3.9121, train accuracy:0.0625.:  15%|█▌        | 15/100 [00:37<02:16,  1.61s/it]\u001b[A\n",
            "train loss:3.9121, train accuracy:0.0625.:  16%|█▌        | 16/100 [00:37<03:52,  2.77s/it]\u001b[A\n",
            "train loss:3.8822, train accuracy:0.0312.:  16%|█▌        | 16/100 [00:38<03:52,  2.77s/it]\u001b[A\n",
            "train loss:3.8822, train accuracy:0.0312.:  17%|█▋        | 17/100 [00:38<02:57,  2.14s/it]\u001b[A\n",
            "train loss:3.8405, train accuracy:0.0625.:  17%|█▋        | 17/100 [00:38<02:57,  2.14s/it]\u001b[A\n",
            "train loss:3.8405, train accuracy:0.0625.:  18%|█▊        | 18/100 [00:38<02:19,  1.70s/it]\u001b[A\n",
            "train loss:3.7115, train accuracy:0.1250.:  18%|█▊        | 18/100 [00:43<02:19,  1.70s/it]\u001b[A\n",
            "train loss:3.7115, train accuracy:0.1250.:  19%|█▉        | 19/100 [00:43<03:29,  2.59s/it]\u001b[A\n",
            "train loss:3.7990, train accuracy:0.0455.:  19%|█▉        | 19/100 [00:44<03:29,  2.59s/it]\u001b[A\n",
            "train loss:3.7990, train accuracy:0.0455.:  20%|██        | 20/100 [00:44<02:39,  2.00s/it]\u001b[A\n",
            "train loss:3.6700, train accuracy:0.0625.:  20%|██        | 20/100 [00:45<02:39,  2.00s/it]\u001b[A\n",
            "train loss:3.6700, train accuracy:0.0625.:  21%|██        | 21/100 [00:45<02:24,  1.83s/it]\u001b[A\n",
            "train loss:3.5394, train accuracy:0.1875.:  21%|██        | 21/100 [00:50<02:24,  1.83s/it]\u001b[A\n",
            "train loss:3.5394, train accuracy:0.1875.:  22%|██▏       | 22/100 [00:50<03:26,  2.65s/it]\u001b[A\n",
            "train loss:3.4954, train accuracy:0.2188.:  22%|██▏       | 22/100 [00:50<03:26,  2.65s/it]\u001b[A\n",
            "train loss:3.4954, train accuracy:0.2188.:  23%|██▎       | 23/100 [00:50<02:38,  2.06s/it]\u001b[A\n",
            "train loss:3.3587, train accuracy:0.3125.:  23%|██▎       | 23/100 [00:51<02:38,  2.06s/it]\u001b[A\n",
            "train loss:3.3587, train accuracy:0.3125.:  24%|██▍       | 24/100 [00:51<02:05,  1.64s/it]\u001b[A\n",
            "train loss:3.4810, train accuracy:0.0909.:  24%|██▍       | 24/100 [00:56<02:05,  1.64s/it]\u001b[A\n",
            "train loss:3.4810, train accuracy:0.0909.:  25%|██▌       | 25/100 [00:56<03:10,  2.54s/it]\u001b[A\n",
            "train loss:3.3477, train accuracy:0.2188.:  25%|██▌       | 25/100 [00:57<03:10,  2.54s/it]\u001b[A\n",
            "train loss:3.3477, train accuracy:0.2188.:  26%|██▌       | 26/100 [00:57<02:43,  2.22s/it]\u001b[A\n",
            "train loss:3.1954, train accuracy:0.2812.:  26%|██▌       | 26/100 [00:58<02:43,  2.22s/it]\u001b[A\n",
            "train loss:3.1954, train accuracy:0.2812.:  27%|██▋       | 27/100 [00:58<02:08,  1.76s/it]\u001b[A\n",
            "train loss:3.1775, train accuracy:0.2500.:  27%|██▋       | 27/100 [01:03<02:08,  1.76s/it]\u001b[A\n",
            "train loss:3.1775, train accuracy:0.2500.:  28%|██▊       | 28/100 [01:03<03:09,  2.64s/it]\u001b[A\n",
            "train loss:3.2145, train accuracy:0.4062.:  28%|██▊       | 28/100 [01:03<03:09,  2.64s/it]\u001b[A\n",
            "train loss:3.2145, train accuracy:0.4062.:  29%|██▉       | 29/100 [01:03<02:25,  2.05s/it]\u001b[A\n",
            "train loss:3.1332, train accuracy:0.4091.:  29%|██▉       | 29/100 [01:04<02:25,  2.05s/it]\u001b[A\n",
            "train loss:3.1332, train accuracy:0.4091.:  30%|███       | 30/100 [01:04<01:53,  1.62s/it]\u001b[A\n",
            "train loss:3.1208, train accuracy:0.2812.:  30%|███       | 30/100 [01:09<01:53,  1.62s/it]\u001b[A\n",
            "train loss:3.1208, train accuracy:0.2812.:  31%|███       | 31/100 [01:09<03:12,  2.80s/it]\u001b[A\n",
            "train loss:2.9644, train accuracy:0.4688.:  31%|███       | 31/100 [01:10<03:12,  2.80s/it]\u001b[A\n",
            "train loss:2.9644, train accuracy:0.4688.:  32%|███▏      | 32/100 [01:10<02:27,  2.16s/it]\u001b[A\n",
            "train loss:2.9351, train accuracy:0.5625.:  32%|███▏      | 32/100 [01:11<02:27,  2.16s/it]\u001b[A\n",
            "train loss:2.9351, train accuracy:0.5625.:  33%|███▎      | 33/100 [01:11<01:55,  1.73s/it]\u001b[A\n",
            "train loss:2.8272, train accuracy:0.4375.:  33%|███▎      | 33/100 [01:16<01:55,  1.73s/it]\u001b[A\n",
            "train loss:2.8272, train accuracy:0.4375.:  34%|███▍      | 34/100 [01:16<02:53,  2.62s/it]\u001b[A\n",
            "train loss:2.9420, train accuracy:0.5000.:  34%|███▍      | 34/100 [01:16<02:53,  2.62s/it]\u001b[A\n",
            "train loss:2.9420, train accuracy:0.5000.:  35%|███▌      | 35/100 [01:16<02:11,  2.02s/it]\u001b[A\n",
            "train loss:2.6918, train accuracy:0.5312.:  35%|███▌      | 35/100 [01:18<02:11,  2.02s/it]\u001b[A\n",
            "train loss:2.6918, train accuracy:0.5312.:  36%|███▌      | 36/100 [01:18<02:00,  1.88s/it]\u001b[A\n",
            "train loss:2.7665, train accuracy:0.4062.:  36%|███▌      | 36/100 [01:22<02:00,  1.88s/it]\u001b[A\n",
            "train loss:2.7665, train accuracy:0.4062.:  37%|███▋      | 37/100 [01:22<02:51,  2.72s/it]\u001b[A\n",
            "train loss:2.6030, train accuracy:0.6562.:  37%|███▋      | 37/100 [01:23<02:51,  2.72s/it]\u001b[A\n",
            "train loss:2.6030, train accuracy:0.6562.:  38%|███▊      | 38/100 [01:23<02:11,  2.12s/it]\u001b[A\n",
            "train loss:2.8131, train accuracy:0.4062.:  38%|███▊      | 38/100 [01:24<02:11,  2.12s/it]\u001b[A\n",
            "train loss:2.8131, train accuracy:0.4062.:  39%|███▉      | 39/100 [01:24<01:43,  1.69s/it]\u001b[A\n",
            "train loss:2.7205, train accuracy:0.3182.:  39%|███▉      | 39/100 [01:28<01:43,  1.69s/it]\u001b[A\n",
            "train loss:2.7205, train accuracy:0.3182.:  40%|████      | 40/100 [01:28<02:35,  2.59s/it]\u001b[A\n",
            "train loss:2.5231, train accuracy:0.5938.:  40%|████      | 40/100 [01:30<02:35,  2.59s/it]\u001b[A\n",
            "train loss:2.5231, train accuracy:0.5938.:  41%|████      | 41/100 [01:30<02:13,  2.27s/it]\u001b[A\n",
            "train loss:2.5077, train accuracy:0.6875.:  41%|████      | 41/100 [01:31<02:13,  2.27s/it]\u001b[A\n",
            "train loss:2.5077, train accuracy:0.6875.:  42%|████▏     | 42/100 [01:31<01:44,  1.80s/it]\u001b[A\n",
            "train loss:2.3794, train accuracy:0.6562.:  42%|████▏     | 42/100 [01:35<01:44,  1.80s/it]\u001b[A\n",
            "train loss:2.3794, train accuracy:0.6562.:  43%|████▎     | 43/100 [01:35<02:33,  2.69s/it]\u001b[A\n",
            "train loss:2.4359, train accuracy:0.5000.:  43%|████▎     | 43/100 [01:36<02:33,  2.69s/it]\u001b[A\n",
            "train loss:2.4359, train accuracy:0.5000.:  44%|████▍     | 44/100 [01:36<01:57,  2.09s/it]\u001b[A\n",
            "train loss:2.3727, train accuracy:0.6364.:  44%|████▍     | 44/100 [01:37<01:57,  2.09s/it]\u001b[A\n",
            "train loss:2.3727, train accuracy:0.6364.:  45%|████▌     | 45/100 [01:37<01:31,  1.66s/it]\u001b[A\n",
            "train loss:2.2970, train accuracy:0.5938.:  45%|████▌     | 45/100 [01:42<01:31,  1.66s/it]\u001b[A\n",
            "train loss:2.2970, train accuracy:0.5938.:  46%|████▌     | 46/100 [01:42<02:32,  2.82s/it]\u001b[A\n",
            "train loss:2.3044, train accuracy:0.5938.:  46%|████▌     | 46/100 [01:43<02:32,  2.82s/it]\u001b[A\n",
            "train loss:2.3044, train accuracy:0.5938.:  47%|████▋     | 47/100 [01:43<01:55,  2.19s/it]\u001b[A\n",
            "train loss:2.2114, train accuracy:0.5938.:  47%|████▋     | 47/100 [01:44<01:55,  2.19s/it]\u001b[A\n",
            "train loss:2.2114, train accuracy:0.5938.:  48%|████▊     | 48/100 [01:44<01:30,  1.74s/it]\u001b[A\n",
            "train loss:2.0711, train accuracy:0.7812.:  48%|████▊     | 48/100 [01:48<01:30,  1.74s/it]\u001b[A\n",
            "train loss:2.0711, train accuracy:0.7812.:  49%|████▉     | 49/100 [01:48<02:14,  2.63s/it]\u001b[A\n",
            "train loss:2.0060, train accuracy:0.7727.:  49%|████▉     | 49/100 [01:49<02:14,  2.63s/it]\u001b[A\n",
            "train loss:2.0060, train accuracy:0.7727.:  50%|█████     | 50/100 [01:49<01:41,  2.04s/it]\u001b[A\n",
            "train loss:2.0970, train accuracy:0.6875.:  50%|█████     | 50/100 [01:51<01:41,  2.04s/it]\u001b[A\n",
            "train loss:2.0970, train accuracy:0.6875.:  51%|█████     | 51/100 [01:51<01:32,  1.90s/it]\u001b[A\n",
            "train loss:1.9852, train accuracy:0.7500.:  51%|█████     | 51/100 [01:55<01:32,  1.90s/it]\u001b[A\n",
            "train loss:1.9852, train accuracy:0.7500.:  52%|█████▏    | 52/100 [01:55<02:11,  2.75s/it]\u001b[A\n",
            "train loss:1.9945, train accuracy:0.7188.:  52%|█████▏    | 52/100 [01:56<02:11,  2.75s/it]\u001b[A\n",
            "train loss:1.9945, train accuracy:0.7188.:  53%|█████▎    | 53/100 [01:56<01:40,  2.14s/it]\u001b[A\n",
            "train loss:1.7826, train accuracy:0.8438.:  53%|█████▎    | 53/100 [01:57<01:40,  2.14s/it]\u001b[A\n",
            "train loss:1.7826, train accuracy:0.8438.:  54%|█████▍    | 54/100 [01:57<01:18,  1.71s/it]\u001b[A\n",
            "train loss:1.8246, train accuracy:0.8182.:  54%|█████▍    | 54/100 [02:01<01:18,  1.71s/it]\u001b[A\n",
            "train loss:1.8246, train accuracy:0.8182.:  55%|█████▌    | 55/100 [02:01<01:56,  2.59s/it]\u001b[A\n",
            "train loss:1.7337, train accuracy:0.7500.:  55%|█████▌    | 55/100 [02:03<01:56,  2.59s/it]\u001b[A\n",
            "train loss:1.7337, train accuracy:0.7500.:  56%|█████▌    | 56/100 [02:03<01:39,  2.26s/it]\u001b[A\n",
            "train loss:1.9151, train accuracy:0.6250.:  56%|█████▌    | 56/100 [02:04<01:39,  2.26s/it]\u001b[A\n",
            "train loss:1.9151, train accuracy:0.6250.:  57%|█████▋    | 57/100 [02:04<01:17,  1.81s/it]\u001b[A\n",
            "train loss:1.5790, train accuracy:0.8438.:  57%|█████▋    | 57/100 [02:08<01:17,  1.81s/it]\u001b[A\n",
            "train loss:1.5790, train accuracy:0.8438.:  58%|█████▊    | 58/100 [02:08<01:52,  2.69s/it]\u001b[A\n",
            "train loss:1.6194, train accuracy:0.9062.:  58%|█████▊    | 58/100 [02:09<01:52,  2.69s/it]\u001b[A\n",
            "train loss:1.6194, train accuracy:0.9062.:  59%|█████▉    | 59/100 [02:09<01:26,  2.10s/it]\u001b[A\n",
            "train loss:1.8063, train accuracy:0.7727.:  59%|█████▉    | 59/100 [02:10<01:26,  2.10s/it]\u001b[A\n",
            "train loss:1.8063, train accuracy:0.7727.:  60%|██████    | 60/100 [02:10<01:06,  1.66s/it]\u001b[A\n",
            "train loss:1.5284, train accuracy:0.9062.:  60%|██████    | 60/100 [02:15<01:06,  1.66s/it]\u001b[A\n",
            "train loss:1.5284, train accuracy:0.9062.:  61%|██████    | 61/100 [02:15<01:50,  2.84s/it]\u001b[A\n",
            "train loss:1.6158, train accuracy:0.7188.:  61%|██████    | 61/100 [02:16<01:50,  2.84s/it]\u001b[A\n",
            "train loss:1.6158, train accuracy:0.7188.:  62%|██████▏   | 62/100 [02:16<01:23,  2.21s/it]\u001b[A\n",
            "train loss:1.6023, train accuracy:0.7500.:  62%|██████▏   | 62/100 [02:17<01:23,  2.21s/it]\u001b[A\n",
            "train loss:1.6023, train accuracy:0.7500.:  63%|██████▎   | 63/100 [02:17<01:05,  1.77s/it]\u001b[A\n",
            "train loss:1.3394, train accuracy:0.8750.:  63%|██████▎   | 63/100 [02:22<01:05,  1.77s/it]\u001b[A\n",
            "train loss:1.3394, train accuracy:0.8750.:  64%|██████▍   | 64/100 [02:22<01:35,  2.65s/it]\u001b[A\n",
            "train loss:1.6269, train accuracy:0.7727.:  64%|██████▍   | 64/100 [02:22<01:35,  2.65s/it]\u001b[A\n",
            "train loss:1.6269, train accuracy:0.7727.:  65%|██████▌   | 65/100 [02:22<01:12,  2.06s/it]\u001b[A\n",
            "train loss:1.3275, train accuracy:0.8125.:  65%|██████▌   | 65/100 [02:24<01:12,  2.06s/it]\u001b[A\n",
            "train loss:1.3275, train accuracy:0.8125.:  66%|██████▌   | 66/100 [02:24<01:05,  1.91s/it]\u001b[A\n",
            "train loss:1.3597, train accuracy:0.8438.:  66%|██████▌   | 66/100 [02:29<01:05,  1.91s/it]\u001b[A\n",
            "train loss:1.3597, train accuracy:0.8438.:  67%|██████▋   | 67/100 [02:29<01:31,  2.77s/it]\u001b[A\n",
            "train loss:1.3552, train accuracy:0.8750.:  67%|██████▋   | 67/100 [02:29<01:31,  2.77s/it]\u001b[A\n",
            "train loss:1.3552, train accuracy:0.8750.:  68%|██████▊   | 68/100 [02:29<01:08,  2.15s/it]\u001b[A\n",
            "train loss:1.2792, train accuracy:0.9062.:  68%|██████▊   | 68/100 [02:30<01:08,  2.15s/it]\u001b[A\n",
            "train loss:1.2792, train accuracy:0.9062.:  69%|██████▉   | 69/100 [02:30<00:53,  1.73s/it]\u001b[A\n",
            "train loss:1.1366, train accuracy:0.9091.:  69%|██████▉   | 69/100 [02:35<00:53,  1.73s/it]\u001b[A\n",
            "train loss:1.1366, train accuracy:0.9091.:  70%|███████   | 70/100 [02:35<01:18,  2.61s/it]\u001b[A\n",
            "train loss:1.0697, train accuracy:0.9375.:  70%|███████   | 70/100 [02:36<01:18,  2.61s/it]\u001b[A\n",
            "train loss:1.0697, train accuracy:0.9375.:  71%|███████   | 71/100 [02:36<01:06,  2.30s/it]\u001b[A\n",
            "train loss:1.0481, train accuracy:1.0000.:  71%|███████   | 71/100 [02:37<01:06,  2.30s/it]\u001b[A\n",
            "train loss:1.0481, train accuracy:1.0000.:  72%|███████▏  | 72/100 [02:37<00:51,  1.83s/it]\u001b[A\n",
            "train loss:1.1494, train accuracy:0.8125.:  72%|███████▏  | 72/100 [02:42<00:51,  1.83s/it]\u001b[A\n",
            "train loss:1.1494, train accuracy:0.8125.:  73%|███████▎  | 73/100 [02:42<01:12,  2.69s/it]\u001b[A\n",
            "train loss:1.1568, train accuracy:0.8750.:  73%|███████▎  | 73/100 [02:42<01:12,  2.69s/it]\u001b[A\n",
            "train loss:1.1568, train accuracy:0.8750.:  74%|███████▍  | 74/100 [02:42<00:54,  2.11s/it]\u001b[A\n",
            "train loss:1.2190, train accuracy:0.7273.:  74%|███████▍  | 74/100 [02:43<00:54,  2.11s/it]\u001b[A\n",
            "train loss:1.2190, train accuracy:0.7273.:  75%|███████▌  | 75/100 [02:43<00:41,  1.68s/it]\u001b[A\n",
            "train loss:1.0679, train accuracy:0.8438.:  75%|███████▌  | 75/100 [02:49<00:41,  1.68s/it]\u001b[A\n",
            "train loss:1.0679, train accuracy:0.8438.:  76%|███████▌  | 76/100 [02:49<01:08,  2.85s/it]\u001b[A\n",
            "train loss:1.0374, train accuracy:0.8125.:  76%|███████▌  | 76/100 [02:50<01:08,  2.85s/it]\u001b[A\n",
            "train loss:1.0374, train accuracy:0.8125.:  77%|███████▋  | 77/100 [02:50<00:51,  2.23s/it]\u001b[A\n",
            "train loss:1.0678, train accuracy:0.8438.:  77%|███████▋  | 77/100 [02:50<00:51,  2.23s/it]\u001b[A\n",
            "train loss:1.0678, train accuracy:0.8438.:  78%|███████▊  | 78/100 [02:50<00:39,  1.78s/it]\u001b[A\n",
            "train loss:0.8820, train accuracy:0.9688.:  78%|███████▊  | 78/100 [02:55<00:39,  1.78s/it]\u001b[A\n",
            "train loss:0.8820, train accuracy:0.9688.:  79%|███████▉  | 79/100 [02:55<00:56,  2.68s/it]\u001b[A\n",
            "train loss:0.7483, train accuracy:1.0000.:  79%|███████▉  | 79/100 [02:56<00:56,  2.68s/it]\u001b[A\n",
            "train loss:0.7483, train accuracy:1.0000.:  80%|████████  | 80/100 [02:56<00:41,  2.08s/it]\u001b[A\n",
            "train loss:0.9120, train accuracy:0.9375.:  80%|████████  | 80/100 [02:57<00:41,  2.08s/it]\u001b[A\n",
            "train loss:0.9120, train accuracy:0.9375.:  81%|████████  | 81/100 [02:57<00:36,  1.93s/it]\u001b[A\n",
            "train loss:0.7871, train accuracy:0.9375.:  81%|████████  | 81/100 [03:02<00:36,  1.93s/it]\u001b[A\n",
            "train loss:0.7871, train accuracy:0.9375.:  82%|████████▏ | 82/100 [03:02<00:49,  2.77s/it]\u001b[A\n",
            "train loss:0.8771, train accuracy:0.9062.:  82%|████████▏ | 82/100 [03:03<00:49,  2.77s/it]\u001b[A\n",
            "train loss:0.8771, train accuracy:0.9062.:  83%|████████▎ | 83/100 [03:03<00:36,  2.17s/it]\u001b[A\n",
            "train loss:0.8763, train accuracy:0.8750.:  83%|████████▎ | 83/100 [03:04<00:36,  2.17s/it]\u001b[A\n",
            "train loss:0.8763, train accuracy:0.8750.:  84%|████████▍ | 84/100 [03:04<00:27,  1.75s/it]\u001b[A\n",
            "train loss:0.6067, train accuracy:0.9545.:  84%|████████▍ | 84/100 [03:08<00:27,  1.75s/it]\u001b[A\n",
            "train loss:0.6067, train accuracy:0.9545.:  85%|████████▌ | 85/100 [03:08<00:39,  2.65s/it]\u001b[A\n",
            "train loss:0.7006, train accuracy:0.9688.:  85%|████████▌ | 85/100 [03:10<00:39,  2.65s/it]\u001b[A\n",
            "train loss:0.7006, train accuracy:0.9688.:  86%|████████▌ | 86/100 [03:10<00:32,  2.33s/it]\u001b[A\n",
            "train loss:0.6624, train accuracy:1.0000.:  86%|████████▌ | 86/100 [03:11<00:32,  2.33s/it]\u001b[A\n",
            "train loss:0.6624, train accuracy:1.0000.:  87%|████████▋ | 87/100 [03:11<00:24,  1.87s/it]\u001b[A\n",
            "train loss:0.8098, train accuracy:0.9375.:  87%|████████▋ | 87/100 [03:15<00:24,  1.87s/it]\u001b[A\n",
            "train loss:0.8098, train accuracy:0.9375.:  88%|████████▊ | 88/100 [03:15<00:32,  2.75s/it]\u001b[A\n",
            "train loss:0.5705, train accuracy:0.9688.:  88%|████████▊ | 88/100 [03:16<00:32,  2.75s/it]\u001b[A\n",
            "train loss:0.5705, train accuracy:0.9688.:  89%|████████▉ | 89/100 [03:16<00:23,  2.15s/it]\u001b[A\n",
            "train loss:0.5460, train accuracy:1.0000.:  89%|████████▉ | 89/100 [03:17<00:23,  2.15s/it]\u001b[A\n",
            "train loss:0.5460, train accuracy:1.0000.:  90%|█████████ | 90/100 [03:17<00:17,  1.72s/it]\u001b[A\n",
            "train loss:0.4272, train accuracy:1.0000.:  90%|█████████ | 90/100 [03:23<00:17,  1.72s/it]\u001b[A\n",
            "train loss:0.4272, train accuracy:1.0000.:  91%|█████████ | 91/100 [03:23<00:25,  2.89s/it]\u001b[A\n",
            "train loss:0.6988, train accuracy:0.9375.:  91%|█████████ | 91/100 [03:23<00:25,  2.89s/it]\u001b[A\n",
            "train loss:0.6988, train accuracy:0.9375.:  92%|█████████▏| 92/100 [03:23<00:18,  2.25s/it]\u001b[A\n",
            "train loss:0.5482, train accuracy:1.0000.:  92%|█████████▏| 92/100 [03:24<00:18,  2.25s/it]\u001b[A\n",
            "train loss:0.5482, train accuracy:1.0000.:  93%|█████████▎| 93/100 [03:24<00:12,  1.81s/it]\u001b[A\n",
            "train loss:0.5559, train accuracy:1.0000.:  93%|█████████▎| 93/100 [03:29<00:12,  1.81s/it]\u001b[A\n",
            "train loss:0.5559, train accuracy:1.0000.:  94%|█████████▍| 94/100 [03:29<00:16,  2.71s/it]\u001b[A\n",
            "train loss:0.7349, train accuracy:0.9545.:  94%|█████████▍| 94/100 [03:30<00:16,  2.71s/it]\u001b[A\n",
            "train loss:0.7349, train accuracy:0.9545.:  95%|█████████▌| 95/100 [03:30<00:10,  2.11s/it]\u001b[A\n",
            "train loss:0.4303, train accuracy:1.0000.:  95%|█████████▌| 95/100 [03:31<00:10,  2.11s/it]\u001b[A\n",
            "train loss:0.4303, train accuracy:1.0000.:  96%|█████████▌| 96/100 [03:31<00:07,  1.95s/it]\u001b[A\n",
            "train loss:0.5396, train accuracy:1.0000.:  96%|█████████▌| 96/100 [03:36<00:07,  1.95s/it]\u001b[A\n",
            "train loss:0.5396, train accuracy:1.0000.:  97%|█████████▋| 97/100 [03:36<00:08,  2.82s/it]\u001b[A\n",
            "train loss:0.5403, train accuracy:1.0000.:  97%|█████████▋| 97/100 [03:37<00:08,  2.82s/it]\u001b[A\n",
            "train loss:0.5403, train accuracy:1.0000.:  98%|█████████▊| 98/100 [03:37<00:04,  2.21s/it]\u001b[A\n",
            "train loss:0.4334, train accuracy:1.0000.:  98%|█████████▊| 98/100 [03:38<00:04,  2.21s/it]\u001b[A\n",
            "train loss:0.4334, train accuracy:1.0000.:  99%|█████████▉| 99/100 [03:38<00:01,  1.78s/it]\u001b[A\n",
            "train loss:0.3877, train accuracy:1.0000.:  99%|█████████▉| 99/100 [03:42<00:01,  1.78s/it]\u001b[A\n",
            "train loss:0.3877, train accuracy:1.0000.: 100%|██████████| 100/100 [03:43<00:00,  2.23s/it]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZItH2lX7k4Yt"
      },
      "source": [
        "You may not see any improvement for your classification task, but unfreezing can help convergence for more difficult image classification tasks."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XAXHAUf3EEiE"
      },
      "source": [
        "## 2 Fine-tune a language model - (15 min)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yu9usOxtjFHL"
      },
      "source": [
        "In this section you will use the gpt-2-simple package [here](https://github.com/minimaxir/gpt-2-simple) to fine-tune the GPT-2 language model on a domain of your choice."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_K7F19SPQo6U"
      },
      "source": [
        "### 2.1 Generate text from an the pretrained GPT-2 model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YLXvK51RnuL"
      },
      "source": [
        "#### Run this code to generate text from a pretrained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDNOb_H5IRvH",
        "outputId": "5f00b014-1f70-41f3-8078-93d046681f66"
      },
      "source": [
        "!pip install gpt-2-simple\n",
        "\n",
        "# the transformers package is built on top of Tensorflow, and the default TF version \n",
        "# for Colab will soon switch to 2.x. We remedy this with the following magic method\n",
        "%tensorflow_version 1.x \n",
        "\n",
        "import gpt_2_simple as gpt2\n",
        "import os\n",
        "import tensorflow as tf"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gpt-2-simple in /usr/local/lib/python3.7/dist-packages (0.8.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from gpt-2-simple) (4.62.3)\n",
            "Requirement already satisfied: tensorflow>=2.5.1 in /usr/local/lib/python3.7/dist-packages (from gpt-2-simple) (2.6.0)\n",
            "Requirement already satisfied: toposort in /usr/local/lib/python3.7/dist-packages (from gpt-2-simple) (1.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from gpt-2-simple) (2.23.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from gpt-2-simple) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from gpt-2-simple) (1.19.5)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.37.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (1.41.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (3.17.3)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (0.12.0)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (1.1.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (0.2.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (1.12)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (3.3.0)\n",
            "Requirement already satisfied: keras~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (2.6.0)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (1.12.1)\n",
            "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (0.4.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (1.1.2)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (0.37.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (1.6.3)\n",
            "Requirement already satisfied: tensorboard~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (2.6.0)\n",
            "Requirement already satisfied: clang~=5.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (5.0)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (3.7.4.3)\n",
            "Requirement already satisfied: tensorflow-estimator~=2.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow>=2.5.1->gpt-2-simple) (2.6.0)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow>=2.5.1->gpt-2-simple) (1.5.2)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.1->gpt-2-simple) (1.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.1->gpt-2-simple) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.1->gpt-2-simple) (3.3.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.1->gpt-2-simple) (0.6.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.1->gpt-2-simple) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.1->gpt-2-simple) (0.4.6)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.6->tensorflow>=2.5.1->gpt-2-simple) (57.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow>=2.5.1->gpt-2-simple) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow>=2.5.1->gpt-2-simple) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow>=2.5.1->gpt-2-simple) (4.2.4)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.5.1->gpt-2-simple) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.5.1->gpt-2-simple) (4.8.1)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.6->tensorflow>=2.5.1->gpt-2-simple) (0.4.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gpt-2-simple) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gpt-2-simple) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gpt-2-simple) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gpt-2-simple) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.6->tensorflow>=2.5.1->gpt-2-simple) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.6->tensorflow>=2.5.1->gpt-2-simple) (3.6.0)\n",
            "TensorFlow 1.x selected.\n",
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aRJ-c9uRMOa",
        "outputId": "33b067d5-a5e0-40e7-8d57-0b5b56ca7555"
      },
      "source": [
        "# This line is necessary to be able to run a new tf session\n",
        "tf.reset_default_graph()\n",
        "# The medium-sized model. IF you run out of memory, try \"124M\" instead\n",
        "model_name = \"124M\"\n",
        "if not os.path.isdir(os.path.join(\"models\", model_name)):\n",
        "\tprint(f\"Downloading {model_name} model...\")\n",
        "\tgpt2.download_gpt2(model_name=model_name)   # model is saved into current directory under /models/124M/\n",
        "\n",
        "sess = gpt2.start_tf_sess()\n",
        "gpt2.load_gpt2(sess, model_name=model_name)\n",
        "gpt2.generate(sess, model_name=model_name)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading pretrained model models/124M/model.ckpt\n",
            "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n",
            "The first eight months of the Trump administration have been a ragged mess. The first eight months of the Trump administration have been a ragged mess.\n",
            "\n",
            "But there's hope the Trump administration is just beginning to let up.\n",
            "\n",
            "Trump has dismissed the idea that his predecessor Barack Obama had any problems with Russian election meddling. Instead, he's blamed Russia for the election itself. And he's blamed his Democratic rival Hillary Clinton, a close friend of Putin.\n",
            "\n",
            "Now, on to the failures:\n",
            "\n",
            "1. The Office of Government Ethics was forced to deploy a list of tough new rules that will apply to any agency who has a conflict of interest.\n",
            "\n",
            "The rules are set to roll back many of the workplace protections that have been championed by President Trump, including the right to file complaints to Congress and the right to sue the government.\n",
            "\n",
            "He also said the rules will make it easier for him to avoid conflicts of interest.\n",
            "\n",
            "But they also limit the power of the attorney general to sue for misconduct.\n",
            "\n",
            "He's also ordered the Department of Justice to disclose whether the Justice Department has any conflicts of interest or conflicts of interest with respect to certain government agencies.\n",
            "\n",
            "2. Trump campaign advisers had their personal emails leaked to the media, which isn't new for this administration. Trump aides have been leaking information to the media. But the campaign has since alleged that it was done to try to help Trump win the election.\n",
            "\n",
            "The New York Times reported last month that the Trump campaign was intentionally trying to distract from their failure to disclose the AG's emails to journalists.\n",
            "\n",
            "The actual investigation into the leaks began in December, when the Washington Post obtained an email from a campaign adviser that detailed his or her contacts with the Russians.\n",
            "\n",
            "The Times reported that the person suggested that the campaign had been trying to help Trump win because getting the emails out was a good idea. But in the email, he wrote:\n",
            "\n",
            "\"We need to get out of the way so we can get to work. We need to get out of the way so we can get to work. That's why why we need to get out from under all of these folks. We need to get out so we can get to work. We need to get out from under all of these folks.\"\n",
            "\n",
            "He also wrote that he thought he was a good candidate for a senior position in the White House, but he was not.\n",
            "\n",
            "The Times story points out that after the Trump campaign published the email exchange the campaign did not tell the FBI, which is working with the FBI on the investigation. The Journal reported that they were under the influence of the Russian government.\n",
            "\n",
            "3. The Trump team lost money from a scheme to get rid of a book that got published in Russia, which is a different story from something Trump described in the campaign. The Trump team lost money from a scheme to get rid of a book that got published in Russia, which is a different story from something Trump described in the campaign.\n",
            "\n",
            "Trump and his team were trying to avoid the media's attention when the Russia story first broke. But they lost money from a scheme to get rid of a book that got published in Russia, which is a different story from something Trump described in the campaign.\n",
            "\n",
            "The Times article notes that the campaign's campaign manager, Corey Lewandowski, wrote a letter to the Times in early March that said, \"We have to move to high ground. We need to get it out of the way so we can get to work. We need to get out of the way so we can get to work. That's why we need to get out from under all of these folks. We need to get out from under all of these folks.\"\n",
            "\n",
            "The campaign said in a statement that the campaign \"loses $25,000 to $40,000 from their campaign-related campaign expenditures\" to out-of-pocket costs.\n",
            "\n",
            "4. The foundation of Trump University, a private, religious nonprofit founded by his son-in-law, Steve Bannon, reportedly had several employees who had ties to the Kremlin, including one who was the head of the Russia program.\n",
            "\n",
            "The foundation's executive director, Arbutus Arbutus, was found guilty last year of defrauding the foundation of a total of $35,000.\n",
            "\n",
            "The foundation has since apologized for its role in the scandal, which led to the resignation of Trump's campaign chairman, Paul Manafort.\n",
            "\n",
            "5. Trump and his team are reportedly getting into a fight over a $10 million loan from the Obama administration. In an interview with the Washington Post last week, Trump said that the State Department should have known that his predecessor had \"a very good track record in foreign policy.\"\n",
            "\n",
            "The program, which has helped students and families of Syrian refugees, is in its third year and has helped thousands of Syrians avoid persecution.\n",
            "\n",
            "A similar loan from the Obama administration was approved in 2014 for $1.4 million and was completed in 2016.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AHmjSVf_FNHv"
      },
      "source": [
        "### 2.2 Download a text dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gPXJkNubFyY6"
      },
      "source": [
        "#### TODO:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KWkuRjbcFzwb"
      },
      "source": [
        "- Use the provided functions to download your own text dataset\n",
        "- [Project Gutenberg](https://www.gutenberg.org/) is a nice starting point for raw text corpora"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iD45m3IwF9hh"
      },
      "source": [
        "#### Download Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESltl2QM5nxw",
        "outputId": "0d2167b1-e6f4-489d-d72b-2ba9e012b7f3"
      },
      "source": [
        "import zipfile\n",
        "import os\n",
        "from torchvision import datasets\n",
        "\n",
        "def extract_zip(zip_path, remove_finished=True):\n",
        "    print('Extracting {}'.format(zip_path))\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(zip_path.replace('.zip', ''))\n",
        "    if remove_finished:\n",
        "        os.remove(zip_path)\n",
        "\n",
        "def download_dataset(url, root='../data'):\n",
        "    if not os.path.exists(os.path.join(root, 'text')):\n",
        "        os.makedirs(os.path.join(root))\n",
        "        datasets.utils.download_url(url, root, 'text.zip', None)\n",
        "        extract_zip(os.path.join(root, 'text.zip'))\n",
        "    return os.path.join(root, 'text')\n",
        "\n",
        "##########################################\n",
        "# Set the url for your dataset here,\n",
        "# move the dataset to the desired location\n",
        "##########################################\n",
        "url = 'https://www.gutenberg.org/files/30/30.zip'\n",
        "download_dataset(url)\n",
        "!mv /data/text/30.txt /data/text/bible.txt\n",
        "!ls ../data/text"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mv: cannot stat '/data/text/30.txt': No such file or directory\n",
            "bible.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "usQE-rSPZq_X"
      },
      "source": [
        "### 2.3 Fine-tune GPT-2 on your own dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IoA0tZZCa_1k"
      },
      "source": [
        "#### TODO:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OoU6ML1mbgjP"
      },
      "source": [
        "- Swap out the dataset parameter with the path to your dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8pa5vFJ5EUjv"
      },
      "source": [
        "#### Train on your dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "WuQ5snl4LuS0",
        "outputId": "c426a95f-fafc-4a43-f489-197ab1c942d5"
      },
      "source": [
        "# This line is necessary to be able to run a new tf session if one has already been run\n",
        "tf.reset_default_graph()\n",
        "# Start a session\n",
        "sess = gpt2.start_tf_sess()\n",
        "# Fine tune `model_name` on `data`\n",
        "###################################\n",
        "# Swap out the `dataset` parameter with the path to your text dataset\n",
        "###################################\n",
        "gpt2.finetune(sess,\n",
        "              dataset='../data/text/bible.txt',\n",
        "              model_name=model_name,\n",
        "              restore_from='latest',\n",
        "              steps=500)   # steps is max number of training steps\n",
        "\n",
        "gpt2.generate(sess, run_name='run1')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/gpt_2_simple/src/sample.py:17: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Loading checkpoint models/124M/model.ckpt\n",
            "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n",
            "Loading dataset...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1/1 [00:07<00:00,  7.96s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dataset has 1788810 tokens\n",
            "Training...\n",
            "[1 | 10.63] loss=2.19 avg=2.19\n",
            "[2 | 14.99] loss=2.52 avg=2.36\n",
            "[3 | 19.35] loss=2.77 avg=2.50\n",
            "[4 | 23.69] loss=1.95 avg=2.36\n",
            "[5 | 28.07] loss=2.01 avg=2.29\n",
            "[6 | 32.44] loss=1.91 avg=2.22\n",
            "[7 | 36.79] loss=1.98 avg=2.19\n",
            "[8 | 41.17] loss=1.89 avg=2.15\n",
            "[9 | 45.55] loss=1.91 avg=2.12\n",
            "[10 | 49.94] loss=1.84 avg=2.09\n",
            "[11 | 54.31] loss=1.93 avg=2.08\n",
            "[12 | 58.69] loss=1.79 avg=2.05\n",
            "[13 | 63.08] loss=1.82 avg=2.03\n",
            "[14 | 67.47] loss=1.74 avg=2.01\n",
            "[15 | 71.86] loss=1.89 avg=2.00\n",
            "[16 | 76.28] loss=1.87 avg=1.99\n",
            "[17 | 80.65] loss=1.73 avg=1.98\n",
            "[18 | 85.02] loss=1.90 avg=1.97\n",
            "[19 | 89.41] loss=1.84 avg=1.96\n",
            "[20 | 93.82] loss=1.80 avg=1.95\n",
            "[21 | 98.22] loss=1.73 avg=1.94\n",
            "[22 | 102.61] loss=1.85 avg=1.94\n",
            "[23 | 107.01] loss=1.78 avg=1.93\n",
            "[24 | 111.40] loss=1.95 avg=1.93\n",
            "[25 | 115.79] loss=1.71 avg=1.92\n",
            "[26 | 120.18] loss=1.82 avg=1.92\n",
            "[27 | 124.57] loss=1.84 avg=1.91\n",
            "[28 | 128.96] loss=1.91 avg=1.91\n",
            "[29 | 133.36] loss=1.67 avg=1.90\n",
            "[30 | 137.75] loss=1.75 avg=1.90\n",
            "[31 | 142.14] loss=1.77 avg=1.89\n",
            "[32 | 146.54] loss=1.79 avg=1.89\n",
            "[33 | 150.93] loss=1.78 avg=1.89\n",
            "[34 | 155.33] loss=1.70 avg=1.88\n",
            "[35 | 159.75] loss=1.79 avg=1.88\n",
            "[36 | 164.14] loss=1.70 avg=1.87\n",
            "[37 | 168.53] loss=1.91 avg=1.87\n",
            "[38 | 172.93] loss=1.68 avg=1.87\n",
            "[39 | 177.33] loss=1.76 avg=1.86\n",
            "[40 | 181.72] loss=1.74 avg=1.86\n",
            "[41 | 186.10] loss=1.75 avg=1.86\n",
            "[42 | 190.50] loss=1.64 avg=1.85\n",
            "[43 | 194.89] loss=1.91 avg=1.85\n",
            "[44 | 199.29] loss=1.73 avg=1.85\n",
            "[45 | 203.69] loss=1.68 avg=1.84\n",
            "[46 | 208.08] loss=1.73 avg=1.84\n",
            "[47 | 212.48] loss=1.70 avg=1.84\n",
            "[48 | 216.88] loss=1.72 avg=1.83\n",
            "[49 | 221.28] loss=1.72 avg=1.83\n",
            "[50 | 225.69] loss=1.76 avg=1.83\n",
            "[51 | 230.07] loss=1.58 avg=1.82\n",
            "[52 | 234.46] loss=1.78 avg=1.82\n",
            "[53 | 238.85] loss=1.78 avg=1.82\n",
            "[54 | 243.24] loss=1.73 avg=1.82\n",
            "[55 | 247.64] loss=1.81 avg=1.82\n",
            "[56 | 252.03] loss=1.70 avg=1.82\n",
            "[57 | 256.44] loss=1.69 avg=1.81\n",
            "[58 | 260.82] loss=1.73 avg=1.81\n",
            "[59 | 265.22] loss=1.77 avg=1.81\n",
            "[60 | 269.63] loss=1.60 avg=1.80\n",
            "[61 | 274.02] loss=1.70 avg=1.80\n",
            "[62 | 278.43] loss=1.77 avg=1.80\n",
            "[63 | 282.82] loss=1.77 avg=1.80\n",
            "[64 | 287.21] loss=1.74 avg=1.80\n",
            "[65 | 291.62] loss=1.61 avg=1.80\n",
            "[66 | 296.01] loss=1.75 avg=1.79\n",
            "[67 | 300.41] loss=1.67 avg=1.79\n",
            "[68 | 304.81] loss=1.63 avg=1.79\n",
            "[69 | 309.20] loss=1.56 avg=1.78\n",
            "[70 | 313.59] loss=1.67 avg=1.78\n",
            "[71 | 317.98] loss=1.66 avg=1.78\n",
            "[72 | 322.36] loss=1.73 avg=1.78\n",
            "[73 | 326.76] loss=1.70 avg=1.78\n",
            "[74 | 331.16] loss=1.68 avg=1.78\n",
            "[75 | 335.56] loss=1.76 avg=1.78\n",
            "[76 | 339.94] loss=1.74 avg=1.77\n",
            "[77 | 344.34] loss=1.64 avg=1.77\n",
            "[78 | 348.76] loss=1.63 avg=1.77\n",
            "[79 | 353.15] loss=1.67 avg=1.77\n",
            "[80 | 357.55] loss=1.79 avg=1.77\n",
            "[81 | 361.92] loss=1.78 avg=1.77\n",
            "[82 | 366.32] loss=1.59 avg=1.77\n",
            "[83 | 370.72] loss=1.68 avg=1.76\n",
            "[84 | 375.11] loss=1.53 avg=1.76\n",
            "[85 | 379.51] loss=1.54 avg=1.76\n",
            "[86 | 383.91] loss=1.60 avg=1.75\n",
            "[87 | 388.31] loss=1.73 avg=1.75\n",
            "[88 | 392.70] loss=1.65 avg=1.75\n",
            "[89 | 397.10] loss=1.71 avg=1.75\n",
            "[90 | 401.50] loss=1.60 avg=1.75\n",
            "[91 | 405.89] loss=1.55 avg=1.74\n",
            "[92 | 410.27] loss=1.74 avg=1.74\n",
            "[93 | 414.66] loss=1.63 avg=1.74\n",
            "[94 | 419.05] loss=1.68 avg=1.74\n",
            "[95 | 423.43] loss=1.58 avg=1.74\n",
            "[96 | 427.82] loss=1.56 avg=1.74\n",
            "[97 | 432.22] loss=1.68 avg=1.73\n",
            "[98 | 436.60] loss=1.68 avg=1.73\n",
            "[99 | 441.01] loss=1.72 avg=1.73\n",
            "[100 | 445.42] loss=1.60 avg=1.73\n",
            "======== SAMPLE 1 ========\n",
            ": ੰُـ:\n",
            "\n",
            "19:009:020:038 For the earth cometh, and all the stars thereof be\n",
            "              in their place, and there is light therein,\n",
            "\n",
            "19:009:021:001 And there is light in the stars that are within, that there\n",
            "              may be light from afar.\n",
            "\n",
            "19:009:022:001 The stars which are within are not in the light, nor\n",
            "             in a light from another.\n",
            "\n",
            "19:009:022:002 Therefore shall ye make an altar of the LORD upon the mountain\n",
            "              of Zion, and an altar of the LORD upon the hill, and an\n",
            "             altar to the mountains of the LORD of hosts.\n",
            "\n",
            "19:009:023:001 Therefore shall ye offer sacrifices in their stead, and\n",
            "             in their place, and unto the LORD, and unto the LORD\n",
            "             of hosts; in their place also ye will put down\n",
            "             the sacrifices offering, saying, Behold, the altar shall\n",
            "            be made one of the mountains, the altar of the LORD of hosts\n",
            "            upon the hill.\n",
            "\n",
            "19:009:023:002 As Moses had said, Thus saith the LORD; These\n",
            "            words will I tell all nations in Israel that the God of the\n",
            "            Israel, whom the LORD hath given to all his people, the LORD of hosts\n",
            "            and the firstbornborn, will I call thee this day, saying, When shall the\n",
            "            LORD of hosts say, Bring unto me the LORD on the mount? And\n",
            "            when he shall say, Bring me the LORD of hosts: and when he shall\n",
            "            say, Bring me from the altar, he shall call thee unto\n",
            "            the LORD of hosts.\n",
            "\n",
            "19:009:024:001 But ye shall offer sacrifices of sacrifice that are in their\n",
            "             stead, unto the LORD, in the manner of the mountains;\n",
            "\n",
            "19:009:024:002 And in their place ye will bring unto the LORD any offering of\n",
            "             the LORD of hosts that are within you, and to all that is\n",
            "             among you.\n",
            "\n",
            "19:009:025:002 And ye shall have a sacrifice of sacrifice; ye shall\n",
            "            have a sacrifice of sacrifice offering on the hill, in their place.\n",
            "\n",
            "19:009:025:003 Therefore ye shall worship at the altar on the hill, and\n",
            "            under the altar the sacrifices of sacrifice will I sing in their\n",
            "            place.\n",
            "\n",
            "19:009:025:004 And ye shall make offerings of sacrifice upon the earth, and\n",
            "            there will also be an offering of sacrifice,\n",
            "            of the LORD of hosts, unto the LORD of hosts.\n",
            "\n",
            "19:009:026:001 And ye shall offer sacrifices of sacrifice on the altar,\n",
            "           in their place, upon the wall, and upon the door, and upon the\n",
            "           altar, before the altar.\n",
            "\n",
            "19:009:026:002 And ye shall offer sacrifices of sacrifice upon the top of the\n",
            "           rock, with the image of the LORD upon the altar;\n",
            "\n",
            "19:009:026:003 And thou will have a sacrifice of sacrifice on the rock, wherein\n",
            "           every one that standeth the last day shall say, I am a servant\n",
            "           of the LORD of hosts.\n",
            "\n",
            "19:009:026:004 Ye shall make offerings unto the LORD of hosts upon the\n",
            " \n",
            "\n",
            "[101 | 468.30] loss=1.60 avg=1.73\n",
            "[102 | 472.68] loss=1.89 avg=1.73\n",
            "[103 | 477.07] loss=1.73 avg=1.73\n",
            "[104 | 481.47] loss=1.62 avg=1.73\n",
            "[105 | 485.86] loss=1.59 avg=1.73\n",
            "[106 | 490.24] loss=1.70 avg=1.73\n",
            "[107 | 494.62] loss=1.54 avg=1.72\n",
            "[108 | 499.01] loss=1.64 avg=1.72\n",
            "[109 | 503.40] loss=1.65 avg=1.72\n",
            "[110 | 507.81] loss=1.71 avg=1.72\n",
            "[111 | 512.20] loss=1.78 avg=1.72\n",
            "[112 | 516.60] loss=1.65 avg=1.72\n",
            "[113 | 520.98] loss=1.67 avg=1.72\n",
            "[114 | 525.38] loss=1.57 avg=1.72\n",
            "[115 | 529.77] loss=1.64 avg=1.72\n",
            "[116 | 534.15] loss=1.68 avg=1.72\n",
            "[117 | 538.55] loss=1.67 avg=1.72\n",
            "[118 | 542.95] loss=1.75 avg=1.72\n",
            "[119 | 547.35] loss=1.43 avg=1.71\n",
            "[120 | 551.74] loss=1.63 avg=1.71\n",
            "[121 | 556.13] loss=1.79 avg=1.71\n",
            "[122 | 560.52] loss=1.67 avg=1.71\n",
            "[123 | 564.93] loss=1.60 avg=1.71\n",
            "[124 | 569.33] loss=1.78 avg=1.71\n",
            "[125 | 573.74] loss=1.55 avg=1.71\n",
            "[126 | 578.14] loss=1.62 avg=1.71\n",
            "[127 | 582.54] loss=1.62 avg=1.71\n",
            "[128 | 586.94] loss=1.53 avg=1.70\n",
            "[129 | 591.34] loss=1.73 avg=1.71\n",
            "[130 | 595.73] loss=1.74 avg=1.71\n",
            "[131 | 600.12] loss=1.68 avg=1.71\n",
            "[132 | 604.51] loss=1.66 avg=1.70\n",
            "[133 | 608.90] loss=1.63 avg=1.70\n",
            "[134 | 613.29] loss=1.70 avg=1.70\n",
            "[135 | 617.68] loss=1.48 avg=1.70\n",
            "[136 | 622.07] loss=1.63 avg=1.70\n",
            "[137 | 626.47] loss=1.57 avg=1.70\n",
            "[138 | 630.85] loss=1.61 avg=1.70\n",
            "[139 | 635.25] loss=1.72 avg=1.70\n",
            "[140 | 639.64] loss=1.78 avg=1.70\n",
            "[141 | 644.04] loss=1.48 avg=1.70\n",
            "[142 | 648.44] loss=1.71 avg=1.70\n",
            "[143 | 652.84] loss=1.64 avg=1.69\n",
            "[144 | 657.23] loss=1.61 avg=1.69\n",
            "[145 | 661.63] loss=1.55 avg=1.69\n",
            "[146 | 666.04] loss=1.73 avg=1.69\n",
            "[147 | 670.44] loss=1.54 avg=1.69\n",
            "[148 | 674.82] loss=1.58 avg=1.69\n",
            "[149 | 679.23] loss=1.55 avg=1.69\n",
            "[150 | 683.61] loss=1.57 avg=1.69\n",
            "[151 | 688.02] loss=1.72 avg=1.69\n",
            "[152 | 692.41] loss=1.36 avg=1.68\n",
            "[153 | 696.81] loss=1.48 avg=1.68\n",
            "[154 | 701.21] loss=1.59 avg=1.68\n",
            "[155 | 705.61] loss=1.67 avg=1.68\n",
            "[156 | 710.00] loss=1.71 avg=1.68\n",
            "[157 | 714.39] loss=1.50 avg=1.68\n",
            "[158 | 718.80] loss=1.63 avg=1.68\n",
            "[159 | 723.19] loss=1.53 avg=1.67\n",
            "[160 | 727.57] loss=1.66 avg=1.67\n",
            "[161 | 731.95] loss=1.52 avg=1.67\n",
            "[162 | 736.35] loss=1.45 avg=1.67\n",
            "[163 | 740.74] loss=1.65 avg=1.67\n",
            "[164 | 745.12] loss=1.65 avg=1.67\n",
            "[165 | 749.52] loss=1.75 avg=1.67\n",
            "[166 | 753.92] loss=1.63 avg=1.67\n",
            "[167 | 758.31] loss=1.70 avg=1.67\n",
            "[168 | 762.70] loss=1.59 avg=1.67\n",
            "[169 | 767.08] loss=1.44 avg=1.67\n",
            "[170 | 771.48] loss=1.56 avg=1.66\n",
            "[171 | 775.89] loss=1.67 avg=1.66\n",
            "[172 | 780.31] loss=1.47 avg=1.66\n",
            "[173 | 784.71] loss=1.52 avg=1.66\n",
            "[174 | 789.10] loss=1.40 avg=1.66\n",
            "[175 | 793.49] loss=1.67 avg=1.66\n",
            "[176 | 797.91] loss=1.61 avg=1.66\n",
            "[177 | 802.31] loss=1.65 avg=1.66\n",
            "[178 | 806.72] loss=1.56 avg=1.66\n",
            "[179 | 811.11] loss=1.46 avg=1.65\n",
            "[180 | 815.50] loss=1.59 avg=1.65\n",
            "[181 | 819.89] loss=1.55 avg=1.65\n",
            "[182 | 824.29] loss=1.60 avg=1.65\n",
            "[183 | 828.68] loss=1.66 avg=1.65\n",
            "[184 | 833.06] loss=1.57 avg=1.65\n",
            "[185 | 837.46] loss=1.63 avg=1.65\n",
            "[186 | 841.84] loss=1.53 avg=1.65\n",
            "[187 | 846.23] loss=1.50 avg=1.65\n",
            "[188 | 850.62] loss=1.41 avg=1.64\n",
            "[189 | 855.02] loss=1.57 avg=1.64\n",
            "[190 | 859.41] loss=1.48 avg=1.64\n",
            "[191 | 863.81] loss=1.73 avg=1.64\n",
            "[192 | 868.23] loss=1.57 avg=1.64\n",
            "[193 | 872.61] loss=1.66 avg=1.64\n",
            "[194 | 877.00] loss=1.66 avg=1.64\n",
            "[195 | 881.41] loss=1.58 avg=1.64\n",
            "[196 | 885.80] loss=1.41 avg=1.64\n",
            "[197 | 890.19] loss=1.68 avg=1.64\n",
            "[198 | 894.59] loss=1.71 avg=1.64\n",
            "[199 | 898.98] loss=1.62 avg=1.64\n",
            "[200 | 903.38] loss=1.68 avg=1.64\n",
            "======== SAMPLE 1 ========\n",
            "        by him and all the saints of God which are in Jerusalem.\n",
            "\n",
            "07:010:010 Behold, now my wife Mary will not be called, nor that I should\n",
            "           also be called upon her name.\n",
            "\n",
            "07:010:011 But I will be called upon to glory as a prophet;\n",
            "           having prophesied in the heart of the whole world, even in the\n",
            "           Holy Ghost!\n",
            "\n",
            "07:010:012\n",
            "\n",
            "07:010:013 For I will rejoice in Christ; and love a good father and a\n",
            "           loving mother: and I will take no pleasure in evil.\n",
            "\n",
            "07:010:014 But I will give a faithful cause unto thee, that thou mayest also be\n",
            "           justified: that I might deliver thee down from the evil that I have\n",
            "           wrought against thee this month.\n",
            "\n",
            "07:010:015 If a man be of a certain habitation, or of a certain tribe or\n",
            "           tribe of men, he is in the kingdom of God; but he shall be\n",
            "           justified for ever.\n",
            "\n",
            "07:010:016\n",
            "\n",
            "07:010:017 I would not make a covenant with thee, as I have done with the\n",
            "           saints of Christ Jesus, and of God: nor would I cast them against\n",
            "           thee, because of thy sins.\n",
            "\n",
            "07:010:018 But I would deliver my son into my hand, as I have done with\n",
            "           Christ Jesus; I would send my hand between my right heart, and my\n",
            "           left, to carry him into the kingdom of God,\n",
            "           that he may be my companion; unto whom ye have sought my counsel\n",
            "           for many years, by\n",
            "           Jesus Christ the Lord.\n",
            "\n",
            "07:010:019 But a man not of the same habitation, or of a certain tribe or\n",
            "            tribe of men, he is not in the kingdom of God; but he\n",
            "           shall be justified for ever.\n",
            "\n",
            "07:010:020 In vain are all men, that they should have no hope for\n",
            "            himself:\n",
            "\n",
            "07:010:021 For as one man hath heareth no power in his hand; but the Lord\n",
            "            giveth life.\n",
            "\n",
            "07:010:022 Therefore are the saints in this present.\n",
            "\n",
            "07:010:023 For I had many wives before; but I shall have none in this\n",
            "           new time to give them again.\n",
            "\n",
            "07:010:024 But now that I have done so without, I am like unto you, that I\n",
            "           are much greater in number, and rejoice in me:\n",
            "\n",
            "07:010:025 But I am now in the glory of the world.\n",
            "\n",
            "07:010:026 I am the God of wrath: and if I have not confidence in me, I\n",
            "           are not justified.\n",
            "\n",
            "07:010:027\n",
            "\n",
            "07:001:001 Blessed be his name, who is with the people, and shall redeem them in\n",
            "           their name, according to their habitation, which they are of.\n",
            "\n",
            "07:001:002 By him that is without, whom ye have sought my counsel, I have done\n",
            "           with you;\n",
            "\n",
            "07:001:003 That I should not have the power of judgment.\n",
            "\n",
            "07:001:004 He that is without shall be likened unto me: and ye that\n",
            "           trust in him shall be likened unto me more by him.\n",
            "\n",
            "07:001:005 And now, O Jerusalem, make no provision for me, if now I\n",
            "           shall not be able to enter upon the kingdom of God.\n",
            "\n",
            "07:001:006 In that the Holy Ghost which I preached unto you, having\n",
            "          \n",
            "\n",
            "[201 | 924.75] loss=1.60 avg=1.64\n",
            "[202 | 929.13] loss=1.52 avg=1.64\n",
            "[203 | 933.53] loss=1.64 avg=1.64\n",
            "[204 | 937.92] loss=1.66 avg=1.64\n",
            "[205 | 942.30] loss=1.55 avg=1.64\n",
            "[206 | 946.71] loss=1.58 avg=1.64\n",
            "interrupted\n",
            "Saving checkpoint/run1/model-206\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gpt_2_simple/gpt_2.py\u001b[0m in \u001b[0;36mfinetune\u001b[0;34m(sess, dataset, steps, model_name, model_dir, combine, batch_size, learning_rate, accumulate_gradients, restore_from, run_name, checkpoint_dir, sample_every, sample_length, sample_num, multi_gpu, save_every, print_every, max_checkpoints, use_memory_saving_gradients, only_train_transformer_layers, optimizer, overwrite, reuse)\u001b[0m\n\u001b[1;32m    339\u001b[0m                     sess.run(\n\u001b[0;32m--> 340\u001b[0;31m                         opt_compute, feed_dict={context: sample_batch()})\n\u001b[0m\u001b[1;32m    341\u001b[0m                 \u001b[0;34m(\u001b[0m\u001b[0mv_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv_summary\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt_apply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msummary_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-407c26f59432>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m               \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m               \u001b[0mrestore_from\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'latest'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m               steps=500)   # steps is max number of training steps\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mgpt2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'run1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gpt_2_simple/gpt_2.py\u001b[0m in \u001b[0;36mfinetune\u001b[0;34m(sess, dataset, steps, model_name, model_dir, combine, batch_size, learning_rate, accumulate_gradients, restore_from, run_name, checkpoint_dir, sample_every, sample_length, sample_num, multi_gpu, save_every, print_every, max_checkpoints, use_memory_saving_gradients, only_train_transformer_layers, optimizer, overwrite, reuse)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'interrupted'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m         \u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gpt_2_simple/gpt_2.py\u001b[0m in \u001b[0;36msave\u001b[0;34m()\u001b[0m\n\u001b[1;32m    284\u001b[0m             \u001b[0msess\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    285\u001b[0m             \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 286\u001b[0;31m             global_step=counter-1)\n\u001b[0m\u001b[1;32m    287\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounter_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    288\u001b[0m             \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcounter\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/training/saver.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self, sess, save_path, global_step, latest_filename, meta_graph_suffix, write_meta_graph, write_state, strip_default_attrs, save_debug_info)\u001b[0m\n\u001b[1;32m   1174\u001b[0m           model_checkpoint_path = sess.run(\n\u001b[1;32m   1175\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msaver_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_tensor_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1176\u001b[0;31m               {self.saver_def.filename_tensor_name: checkpoint_file})\n\u001b[0m\u001b[1;32m   1177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1178\u001b[0m         \u001b[0mmodel_checkpoint_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_checkpoint_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    958\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1178\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1357\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1361\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1363\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1367\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1348\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n\u001b[0;32m-> 1350\u001b[0;31m                                       target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tensorflow-1.15.2/python3.7/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1441\u001b[0m     return tf_session.TF_SessionRun_wrapper(self._session, options, feed_dict,\n\u001b[1;32m   1442\u001b[0m                                             \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1443\u001b[0;31m                                             run_metadata)\n\u001b[0m\u001b[1;32m   1444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1445\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x4iuqczYK2ft"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}